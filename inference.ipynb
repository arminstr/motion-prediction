{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "## This notebook can be used to infere the motion prediction LSTM based on Rasterization\n",
    "\n",
    "\n",
    "Created in July 2021;\n",
    "Author: Armin Straller;\n",
    "Email: armin.straller@hs-augsburg.de\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.signal\n",
    "import cv2 as cv\n",
    "from IPython.display import Image, display\n",
    "from skimage.transform import rescale\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/dev/motion-prediction-cnn/motion-prediction')\n",
    "from convert_single_scenario import tf_example_scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set global dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the location of the scenarios to use for inference. Additionally, define the path to the stored training checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHNAME = '/home/dev/motion-prediction-cnn/motion-prediction/data'\n",
    "checkpoint_path = '/home/dev/motion-prediction-cnn/motion-prediction/training_checkpoints/static-map-100-epochs-1e-1s-custom-loss-kernel-531/cp-0100.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the size of the rasterization grid and the length of the supplied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 128\n",
    "DATA_LENGTH = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Init GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads a scenario defined in the location defined by ***PATHNAME*** and ***scenario_name***. ***last_int(x)*** is used to read in the files in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_int(x):\n",
    "    y = x.split(\"00150_\")\n",
    "    z = y[1].split(\".\")\n",
    "    return(int(z[0]))\n",
    "\n",
    "def load_scenario(n_frames=10):\n",
    "    \"\"\"\n",
    "    load scenarios that were saved using convert_training_data.py\n",
    "    \"\"\"\n",
    "    frames = np.zeros((1, n_frames, GRID_SIZE, GRID_SIZE, 1), dtype=np.float32)\n",
    "\n",
    "    _, _, filenames = next(walk(PATHNAME + '/static_' + scenario_name))\n",
    "    temp_frames = np.zeros((DATA_LENGTH, GRID_SIZE, GRID_SIZE, 1), dtype=np.float32)\n",
    "    \n",
    "    for filename in sorted(filenames, key = last_int)  :\n",
    "        image = imageio.imread(PATHNAME + '/static_' + scenario_name + '/' + filename, as_gray=True)\n",
    "        image = np.reshape(image, (GRID_SIZE,GRID_SIZE,1))\n",
    "        filename_sections = filename.split('_')\n",
    "        filename_index, _ = filename_sections[-1].split('.')\n",
    "        temp_frames[int(filename_index)] = image/255\n",
    "    \n",
    "    frames[0] = temp_frames[0:n_frames]\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for postprocessing of the predicted frame. \n",
    "Every pixel brighter then a certain threshold is considered to be an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_objects(frame):\n",
    "    reduced_max = tf.reduce_max(frame)\n",
    "    reduced_mean = tf.reduce_mean(frame)\n",
    "    threshold_objects = reduced_max * 0.6\n",
    "    mask_objects = tf.math.greater(frame, threshold_objects)\n",
    "    mask_objects = tf.cast(mask_objects, dtype=tf.float32)\n",
    "    return mask_objects * reduced_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***predict_future_frame(frames)*** function uses the prediction interface of the model. The original map is retreived from the scenario definition and the predicted obejects are added to it. This way a good quality of the images passed to the LSTM in the next prediction step can be guaranteed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_frame(frames, correction=False):\n",
    "    pred_frames = seq.predict(frames)\n",
    "\n",
    "    FILEPATH = PATHNAME + '/validation_tfexample.' + scenario_name\n",
    "\n",
    "    scenario_converter = tf_example_scenario(128, 1)\n",
    "    map = scenario_converter.load_map_at(FILEPATH, [0.0, 0.0,0.0], 0, 9)\n",
    "    map = np.expand_dims(map, axis=2)/255\n",
    "\n",
    "    objects = postprocess_objects(pred_frames[0, 9]).numpy()\n",
    "\n",
    "    # use the section below to mask out objetcs from the map\n",
    "    threshold = tf.reduce_max(objects)\n",
    "    mask_objects = tf.math.less(objects, threshold)\n",
    "    mask_objects = tf.cast(mask_objects, dtype=tf.float32)\n",
    "    map_masked = mask_objects * map\n",
    "\n",
    "    prediction = np.add(map_masked, objects)\n",
    "    if correction == False:\n",
    "        # CONTROL: uncommenting the line below disables the prediction data improvement\n",
    "        prediction = pred_frames[0, 9]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a basic model instance. The model is consits of multiple Convolutional LSTM 2D Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(\n",
    "            shape=(10, GRID_SIZE, GRID_SIZE, 1), dtype=\"float32\"\n",
    "        ),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=128, kernel_size=(5, 5), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=128, kernel_size=(1, 1), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv3D(\n",
    "            filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom loss function is used for compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_bright_pixels_custom(y_true, y_pred):\n",
    "    \n",
    "    threshold = tf.reduce_max(y_true) / 2\n",
    "    mask_vehicle = tf.math.greater(y_true, threshold)\n",
    "    mask_map = tf.math.less(y_true, threshold)\n",
    "\n",
    "\n",
    "    mask_vehicle = tf.cast(mask_vehicle, dtype=tf.float32)\n",
    "    mask_map = tf.cast(mask_map, dtype=tf.float32)\n",
    "    y_true_masked_vehicle = mask_vehicle * y_true\n",
    "    y_pred_masked_vehicle =  mask_vehicle * y_pred\n",
    "\n",
    "    # set the true value to zero. this way all other pixels then the vehicles will go black\n",
    "    y_true_masked_map = mask_map * 0.0\n",
    "    y_pred_masked_map =  mask_map * y_pred\n",
    "\n",
    "    squared_difference_vehicle = tf.square(y_true_masked_vehicle - y_pred_masked_vehicle)\n",
    "    squared_difference_map = tf.square(y_true_masked_map - y_pred_masked_map)\n",
    "\n",
    "    return tf.reduce_mean(squared_difference_vehicle, axis=1) * 0.5 + tf.reduce_mean(squared_difference_map, axis=1) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.compile(loss=only_bright_pixels_custom, optimizer=\"adadelta\", metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the model weights from the previously defined training checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 10, 128, 128, 128) 1651712   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 128, 128, 128) 512       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 10, 128, 128, 128) 1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 128, 128, 128) 512       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 10, 128, 128, 128) 131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 128, 128, 128) 512       \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 128, 128, 1)   3457      \n",
      "=================================================================\n",
      "Total params: 2,968,449\n",
      "Trainable params: 2,967,681\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "seq.load_weights(checkpoint_path)\n",
    "seq.summary()\n",
    "\n",
    "print(tf.keras.backend.floatx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Select Scenario for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - **Vehicles driving towards static object**\n",
    "A static object is parked on the right lane. Vehicles slow down for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'tfrecord-00050-of-00150'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - **Few objects**\n",
    "Three objects drive straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'tfrecord-00038-of-00150'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_frames = np.zeros((30, 128, 128, 1))\n",
    "input_frames = load_scenario()\n",
    "updated_input = input_frames\n",
    "# Predict 10 Frames\n",
    "for j in range(10):\n",
    "    # predict single frame and add it to the predicted_frames\n",
    "    predicted_frames[j] = predict_future_frame(updated_input[np.newaxis, 0], correction=False)\n",
    "    updated_input = np.delete(updated_input, 0, 1)\n",
    "    predicted_frame = np.array([predicted_frames[j]])\n",
    "    updated = np.concatenate((updated_input[0], predicted_frame), axis=0)\n",
    "    updated_input = np.zeros((1, 10, 128, 128, 1))\n",
    "    updated_input[0] = updated\n",
    "    \n",
    "    sys.stdout.write(\"\\rPrediction: \" + str(j+1) + \"/10\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# https://stackoverflow.com/questions/25333732/matplotlib-animation-not-working-in-ipython-notebook-blank-plot\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "fig = plt.figure()\n",
    "\n",
    "ims = []\n",
    "for i in range(1, 20):\n",
    "    if i < 10:\n",
    "        im = plt.imshow(input_frames[0][i], animated=True)\n",
    "        ims.append([im])\n",
    "    if i >= 10:\n",
    "        im = plt.imshow(updated_input[0][i-10], animated=True)\n",
    "        ims.append([im])\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'tfrecord-00002-of-00150'\n",
    "FILEPATH = PATHNAME + '/validation_tfexample.' + scenario_name\n",
    "\n",
    "scenario_converter = tf_example_scenario(128, 1)\n",
    "map = scenario_converter.load_map_at(FILEPATH, [0.0, 0.0,0.0], 0, 50)\n",
    "map = np.expand_dims(map, axis=2)/255\n",
    "plt.imshow(map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'tfrecord-00050-of-00150'\n",
    "\n",
    "predicted_frames = np.zeros((30, 128, 128, 1))\n",
    "input_frames = load_scenario()\n",
    "updated_input = input_frames\n",
    "# Predict 10 Frames\n",
    "for j in range(10):\n",
    "    # predict single frame and add it to the predicted_frames\n",
    "    predicted_frames[j] = predict_future_frame(updated_input[np.newaxis, 0], correction=False)\n",
    "    updated_input = np.delete(updated_input, 0, 1)\n",
    "    predicted_frame = np.array([predicted_frames[j]])\n",
    "    updated = np.concatenate((updated_input[0], predicted_frame), axis=0)\n",
    "    updated_input = np.zeros((1, 10, 128, 128, 1))\n",
    "    updated_input[0] = updated\n",
    "    \n",
    "    sys.stdout.write(\"\\rPrediction: \" + str(j+1) + \"/10\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "plt.imshow(input_frames[0][1])\n",
    "plt.show()\n",
    "plt.imshow(input_frames[0][5])\n",
    "plt.show()\n",
    "plt.imshow(input_frames[0][9])\n",
    "plt.show()\n",
    "plt.imshow(updated_input[0][1])\n",
    "plt.show()\n",
    "plt.imshow(updated_input[0][9])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
